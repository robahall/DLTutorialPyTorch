{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import torch\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1 - Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 1280, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_arr = imageio.imread('../data/p1ch4/image-dog/bobby.jpg')\n",
    "img_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch requires: Color x Height x Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.from_numpy(img_arr)\n",
    "out = img.permute(2,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "batch = torch.zeros(batch_size, 3, 256, 256, dtype=torch.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor: Batch x Color x Height x Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('../data/p1ch4/image-cats/')\n",
    "filenames = list(data_dir.glob('*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, filename in enumerate(filenames):\n",
    "    img_arr = imageio.imread(filename)\n",
    "    img_t = torch.from_numpy(img_arr)\n",
    "    img_t = img_t.permute(2,0,1)\n",
    "    img_t = img_t[:3]\n",
    "    batch[idx] = img_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize between 0,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = batch.float()\n",
    "batch /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.7922, 0.7569, 0.7451,  ..., 0.0510, 0.0510, 0.0471],\n",
       "          [0.7804, 0.7529, 0.7412,  ..., 0.0549, 0.0549, 0.0549],\n",
       "          [0.7765, 0.7569, 0.7373,  ..., 0.0471, 0.0471, 0.0471],\n",
       "          ...,\n",
       "          [0.3647, 0.3216, 0.2980,  ..., 0.1412, 0.1412, 0.1412],\n",
       "          [0.2941, 0.2667, 0.3961,  ..., 0.1412, 0.1412, 0.1451],\n",
       "          [0.3333, 0.4039, 0.3529,  ..., 0.1412, 0.1451, 0.1490]],\n",
       "\n",
       "         [[0.5922, 0.5451, 0.5216,  ..., 0.0353, 0.0353, 0.0314],\n",
       "          [0.5922, 0.5490, 0.5255,  ..., 0.0431, 0.0431, 0.0431],\n",
       "          [0.5961, 0.5608, 0.5255,  ..., 0.0431, 0.0431, 0.0431],\n",
       "          ...,\n",
       "          [0.2235, 0.1765, 0.1529,  ..., 0.1020, 0.1020, 0.1020],\n",
       "          [0.1294, 0.1020, 0.2314,  ..., 0.1020, 0.1020, 0.1059],\n",
       "          [0.1569, 0.2275, 0.1765,  ..., 0.1020, 0.1059, 0.1098]],\n",
       "\n",
       "         [[0.2667, 0.2078, 0.1725,  ..., 0.0235, 0.0235, 0.0196],\n",
       "          [0.2627, 0.2118, 0.1725,  ..., 0.0235, 0.0235, 0.0235],\n",
       "          [0.2627, 0.2196, 0.1725,  ..., 0.0235, 0.0235, 0.0235],\n",
       "          ...,\n",
       "          [0.1216, 0.0745, 0.0471,  ..., 0.0667, 0.0667, 0.0667],\n",
       "          [0.0431, 0.0078, 0.1373,  ..., 0.0667, 0.0667, 0.0706],\n",
       "          [0.0745, 0.1451, 0.0863,  ..., 0.0667, 0.0706, 0.0745]]],\n",
       "\n",
       "\n",
       "        [[[0.9333, 0.9333, 0.9333,  ..., 0.8392, 0.8431, 0.8431],\n",
       "          [0.9333, 0.9333, 0.9333,  ..., 0.8392, 0.8431, 0.8431],\n",
       "          [0.9333, 0.9333, 0.9333,  ..., 0.8392, 0.8431, 0.8431],\n",
       "          ...,\n",
       "          [0.8392, 0.8353, 0.8314,  ..., 0.7333, 0.7451, 0.7569],\n",
       "          [0.8392, 0.8353, 0.8314,  ..., 0.7294, 0.7451, 0.7529],\n",
       "          [0.8392, 0.8353, 0.8314,  ..., 0.7294, 0.7451, 0.7529]],\n",
       "\n",
       "         [[0.7647, 0.7647, 0.7647,  ..., 0.6784, 0.6863, 0.6863],\n",
       "          [0.7647, 0.7647, 0.7647,  ..., 0.6784, 0.6863, 0.6863],\n",
       "          [0.7647, 0.7647, 0.7647,  ..., 0.6784, 0.6863, 0.6863],\n",
       "          ...,\n",
       "          [0.5020, 0.4980, 0.4941,  ..., 0.3922, 0.4039, 0.4157],\n",
       "          [0.5020, 0.4980, 0.4941,  ..., 0.3882, 0.4039, 0.4118],\n",
       "          [0.5020, 0.4980, 0.4941,  ..., 0.3882, 0.4039, 0.4118]],\n",
       "\n",
       "         [[0.5373, 0.5373, 0.5373,  ..., 0.4902, 0.4941, 0.4941],\n",
       "          [0.5373, 0.5373, 0.5373,  ..., 0.4902, 0.4941, 0.4941],\n",
       "          [0.5373, 0.5373, 0.5373,  ..., 0.4902, 0.4941, 0.4941],\n",
       "          ...,\n",
       "          [0.3098, 0.3059, 0.3020,  ..., 0.2510, 0.2667, 0.2824],\n",
       "          [0.3098, 0.3059, 0.3020,  ..., 0.2510, 0.2706, 0.2784],\n",
       "          [0.3098, 0.3059, 0.3020,  ..., 0.2549, 0.2706, 0.2824]]],\n",
       "\n",
       "\n",
       "        [[[0.6118, 0.5961, 0.4863,  ..., 0.5882, 0.5843, 0.6196],\n",
       "          [0.6824, 0.5255, 0.6471,  ..., 0.4706, 0.5333, 0.5412],\n",
       "          [0.4980, 0.6118, 0.4196,  ..., 0.5137, 0.5608, 0.6431],\n",
       "          ...,\n",
       "          [0.4549, 0.5098, 0.5059,  ..., 0.4980, 0.4627, 0.4392],\n",
       "          [0.5059, 0.5098, 0.4824,  ..., 0.4510, 0.4745, 0.4471],\n",
       "          [0.5059, 0.4824, 0.4627,  ..., 0.4431, 0.4745, 0.4706]],\n",
       "\n",
       "         [[0.5451, 0.5294, 0.4275,  ..., 0.5294, 0.5294, 0.5765],\n",
       "          [0.6275, 0.4667, 0.5843,  ..., 0.4118, 0.4784, 0.4863],\n",
       "          [0.4431, 0.5490, 0.3529,  ..., 0.4627, 0.5059, 0.5961],\n",
       "          ...,\n",
       "          [0.3882, 0.4314, 0.4353,  ..., 0.4588, 0.4235, 0.4039],\n",
       "          [0.4353, 0.4353, 0.4157,  ..., 0.4157, 0.4392, 0.4118],\n",
       "          [0.4353, 0.4078, 0.4000,  ..., 0.4039, 0.4314, 0.4353]],\n",
       "\n",
       "         [[0.5059, 0.4824, 0.3843,  ..., 0.5137, 0.5176, 0.5686],\n",
       "          [0.6078, 0.4314, 0.5373,  ..., 0.4000, 0.4667, 0.4745],\n",
       "          [0.4078, 0.5176, 0.3137,  ..., 0.4392, 0.4902, 0.5725],\n",
       "          ...,\n",
       "          [0.3647, 0.4235, 0.4118,  ..., 0.4902, 0.4510, 0.4235],\n",
       "          [0.4235, 0.4235, 0.3843,  ..., 0.4314, 0.4588, 0.4314],\n",
       "          [0.4196, 0.3843, 0.3725,  ..., 0.4235, 0.4510, 0.4549]]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize between -1,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels = batch.shape[1]\n",
    "for color in range(n_channels):\n",
    "    mean = torch.mean(batch[:, color])\n",
    "    std = torch.std(batch[:, color])\n",
    "    batch[:, color] = (batch[:, color]-mean)/std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2: Volumetric Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = Path(\"../data/p1ch4/volumetric-dicom/\")\n",
    "dir_path = [x for x in dir_path.iterdir() if x.is_dir()][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading DICOM (examining files): 1/99 files (1.0%99/99 files (100.0%)\n",
      "  Found 1 correct series.\n",
      "Reading DICOM (loading data): 76/99  (76.899/99  (100.0%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(99, 512, 512)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol_arr = imageio.volread(dir_path, 'DICOM')\n",
    "vol_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## No room for a chanel so we need to unsqueeze a dimension (Add a dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol = torch.from_numpy(vol_arr).float()\n",
    "vol = torch.unsqueeze(vol, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 99, 512, 512])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current channels = Color x Depth x Height x Weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3 - Tabular Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_path = Path(\"../data/p1ch4/tabular-wine/winequality-white.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "wineq_np = np.loadtxt(wine_path, dtype=np.float32, delimiter=\";\", skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = next(csv.reader(open(wine_path), delimiter=';'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4898, 12),\n",
       " ['fixed acidity',\n",
       "  'volatile acidity',\n",
       "  'citric acid',\n",
       "  'residual sugar',\n",
       "  'chlorides',\n",
       "  'free sulfur dioxide',\n",
       "  'total sulfur dioxide',\n",
       "  'density',\n",
       "  'pH',\n",
       "  'sulphates',\n",
       "  'alcohol',\n",
       "  'quality'])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wineq_np.shape, col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "wineq = torch.from_numpy(wineq_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4898, 12]), torch.float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wineq.shape, wineq.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7.0000,  0.2700,  0.3600,  ...,  3.0000,  0.4500,  8.8000],\n",
       "         [ 6.3000,  0.3000,  0.3400,  ...,  3.3000,  0.4900,  9.5000],\n",
       "         [ 8.1000,  0.2800,  0.4000,  ...,  3.2600,  0.4400, 10.1000],\n",
       "         ...,\n",
       "         [ 6.5000,  0.2400,  0.1900,  ...,  2.9900,  0.4600,  9.4000],\n",
       "         [ 5.5000,  0.2900,  0.3000,  ...,  3.3400,  0.3800, 12.8000],\n",
       "         [ 6.0000,  0.2100,  0.3800,  ...,  3.2600,  0.3200, 11.8000]]),\n",
       " torch.Size([4898, 11]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = wineq[:, :-1]\n",
    "data, data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([6, 6, 6,  ..., 6, 7, 6]), torch.Size([4898]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = wineq[:, -1].long()\n",
    "target, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_onehot = torch.zeros(target.shape[0], 10)\n",
    "target_onehot.scatter_(1, target.unsqueeze(1), 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ending in _ indicates the method will not return a new tensor, but will modify the tensor in place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6],\n",
       "        [6],\n",
       "        [6],\n",
       "        ...,\n",
       "        [6],\n",
       "        [7],\n",
       "        [6]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With unsqueeze we add a singleton dimension. So from a 1-D tensor (4898) to a 2D tensor (4898 x 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.8548e+00, 2.7824e-01, 3.3419e-01, 6.3914e+00, 4.5772e-02, 3.5308e+01,\n",
       "        1.3836e+02, 9.9403e-01, 3.1883e+00, 4.8985e-01, 1.0514e+01])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_mean = torch.mean(data, dim=0)\n",
    "data_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.1211e-01, 1.0160e-02, 1.4646e-02, 2.5726e+01, 4.7733e-04, 2.8924e+02,\n",
       "        1.8061e+03, 8.9455e-06, 2.2801e-02, 1.3025e-02, 1.5144e+00])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_var = torch.var(data, dim=0)\n",
    "data_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7209e-01, -8.1764e-02,  2.1325e-01,  ..., -1.2468e+00,\n",
       "         -3.4914e-01, -1.3930e+00],\n",
       "        [-6.5743e-01,  2.1587e-01,  4.7991e-02,  ...,  7.3992e-01,\n",
       "          1.3467e-03, -8.2418e-01],\n",
       "        [ 1.4756e+00,  1.7448e-02,  5.4378e-01,  ...,  4.7502e-01,\n",
       "         -4.3677e-01, -3.3662e-01],\n",
       "        ...,\n",
       "        [-4.2042e-01, -3.7940e-01, -1.1915e+00,  ..., -1.3131e+00,\n",
       "         -2.6152e-01, -9.0544e-01],\n",
       "        [-1.6054e+00,  1.1666e-01, -2.8253e-01,  ...,  1.0048e+00,\n",
       "         -9.6250e-01,  1.8574e+00],\n",
       "        [-1.0129e+00, -6.7703e-01,  3.7852e-01,  ...,  4.7502e-01,\n",
       "         -1.4882e+00,  1.0448e+00]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_normalized = (data - data_mean)/torch.sqrt(data_var)\n",
    "data_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4898]), torch.bool, tensor(20))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_indexes = target <=3\n",
    "bad_indexes.shape, bad_indexes.dtype, bad_indexes.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 11])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_data = data[bad_indexes]\n",
    "bad_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_data = data[target <=3]\n",
    "mid_data = data[(target > 3) & (target < 7)]\n",
    "good_data = data[target >= 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_mean = torch.mean(bad_data, dim=0)\n",
    "mid_mean = torch.mean(mid_data, dim=0)\n",
    "good_mean = torch.mean(good_data, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 fixed acidity          7.60   6.89   6.73\n",
      " 1 volatile acidity       0.33   0.28   0.27\n",
      " 2 citric acid            0.34   0.34   0.33\n",
      " 3 residual sugar         6.39   6.71   5.26\n",
      " 4 chlorides              0.05   0.05   0.04\n",
      " 5 free sulfur dioxide   53.33  35.42  34.55\n",
      " 6 total sulfur dioxide 170.60 141.83 125.25\n",
      " 7 density                0.99   0.99   0.99\n",
      " 8 pH                     3.19   3.18   3.22\n",
      " 9 sulphates              0.47   0.49   0.50\n",
      "10 alcohol               10.34  10.26  11.42\n"
     ]
    }
   ],
   "source": [
    "for i, args in enumerate(zip(col_list, bad_mean, mid_mean, good_mean)):\n",
    "    print(\"{:2} {:20} {:6.2f} {:6.2f} {:6.2f}\".format(i, *args))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([17520, 17])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes_np = np.loadtxt(\"../data/p1ch4/bike-sharing-dataset/hour-fixed.csv\",\n",
    "                      dtype=np.float32,\n",
    "                      delimiter = \",\",\n",
    "                      skiprows = 1,\n",
    "                      converters = {1: lambda x: float(x[8:10])}\n",
    "                      )\n",
    "bikes = torch.from_numpy(bikes_np)\n",
    "bikes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 3.0000e+00, 1.3000e+01,\n",
       "         1.6000e+01],\n",
       "        [2.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 8.0000e+00, 3.2000e+01,\n",
       "         4.0000e+01],\n",
       "        [3.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 5.0000e+00, 2.7000e+01,\n",
       "         3.2000e+01],\n",
       "        ...,\n",
       "        [1.7377e+04, 3.1000e+01, 1.0000e+00,  ..., 7.0000e+00, 8.3000e+01,\n",
       "         9.0000e+01],\n",
       "        [1.7378e+04, 3.1000e+01, 1.0000e+00,  ..., 1.3000e+01, 4.8000e+01,\n",
       "         6.1000e+01],\n",
       "        [1.7379e+04, 3.1000e+01, 1.0000e+00,  ..., 1.2000e+01, 3.7000e+01,\n",
       "         4.9000e+01]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need tensor of N x C x L \n",
    "\n",
    "N = Number of observations \n",
    "\n",
    "C = Feature Column\n",
    "\n",
    "L = Hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([17520, 17]), (17, 1))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.shape, bikes.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17520 hours and 17 columns. Reshape so we have 3 axes -> day, hour and our 17 columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_bikes = bikes.view(-1, 24, bikes.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([730, 24, 17]), (408, 17, 1))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_bikes.shape, daily_bikes.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our call to view on a tensor returns a new tensor that changes the number of dimensions and stride info without changing the storage. Use -1 as a placeholder for \"however many indexes are left, given the other dimensions and the original number of elements\"\n",
    "\n",
    "The stride is telling us that by advancing along the hour dimension requires us to advance by 17 places in storage. Advancing by the day dimension requires us to advance by a number of elements equal to the length of a row in the storage times 24 (408 = 17 x 24).\n",
    "\n",
    "Currently aligned  N x L x C. (730, 24, 17). Need to alight it N x C x L. (730, 17, 24)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([730, 17, 24]), (408, 1, 17))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_bikes = daily_bikes.transpose(1,2)\n",
    "daily_bikes.shape, daily_bikes.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_day = bikes[:24].long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_onehot = torch.zeros(first_day.shape[0], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_day[:, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0.],\n",
       "        [1., 0., 1., 0.],\n",
       "        [1., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_onehot.scatter_(dim=1, \n",
    "                        index=first_day[:,9].unsqueeze(1).long() - 1, \n",
    "                        value=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  1.0000,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000,  6.0000,\n",
       "          0.0000,  1.0000,  0.2400,  0.2879,  0.8100,  0.0000,  3.0000, 13.0000,\n",
       "         16.0000,  1.0000,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((bikes[:24], weather_onehot), 1)[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([730, 4, 24])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_weather_onehot = torch.zeros(daily_bikes.shape[0], 4, daily_bikes.shape[2])\n",
    "daily_weather_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([730, 4, 24])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_weather_onehot.scatter_(1, daily_bikes[:,9,:].long().unsqueeze(1)-1, 1.0)\n",
    "daily_weather_onehot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/p1ch4/jane-austen/1342-0.txt', encoding='utf8') as f: \n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'“Impossible, Mr. Bennet, impossible, when I am not acquainted with him'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = text.split(\"\\n\")\n",
    "line = lines[200]\n",
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([70, 128])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letter_t = torch.zeros(len(line), 128)\n",
    "letter_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i , letter in enumerate(line.lower().strip()):\n",
    "    letter_index = ord(letter) if ord(letter) < 128 else 0\n",
    "    letter_t[i][letter_index] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_words(input_str):\n",
    "    punc = '.,;:\"!?”“_-'\n",
    "    word_list = input_str.lower().replace('\\n',' ').split() \n",
    "    word_list = [word.strip(punc) for word in word_list] \n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_in_line = clean_words(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('“Impossible, Mr. Bennet, impossible, when I am not acquainted with him',\n",
       " ['impossible',\n",
       "  'mr',\n",
       "  'bennet',\n",
       "  'impossible',\n",
       "  'when',\n",
       "  'i',\n",
       "  'am',\n",
       "  'not',\n",
       "  'acquainted',\n",
       "  'with',\n",
       "  'him'])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line, words_in_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7261, 3394)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list = sorted(set(clean_words(text)))\n",
    "word2index_dict = {word:i for (i, word) in enumerate(word_list)}\n",
    "\n",
    "len(word2index_dict), word2index_dict['impossible']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 3394 impossible\n",
      " 1 4305 mr\n",
      " 2  813 bennet\n",
      " 3 3394 impossible\n",
      " 4 7078 when\n",
      " 5 3315 i\n",
      " 6  415 am\n",
      " 7 4436 not\n",
      " 8  239 acquainted\n",
      " 9 7148 with\n",
      "10 3215 him\n"
     ]
    }
   ],
   "source": [
    "word_t = torch.zeros(len(words_in_line), len(word2index_dict))\n",
    "for i, word in enumerate(words_in_line):\n",
    "    word_index = word2index_dict[word]\n",
    "    word_t[i][word_index]=1\n",
    "    print('{:2} {:4} {}'.format(i, word_index, word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11, 7261])\n"
     ]
    }
   ],
   "source": [
    "print(word_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
