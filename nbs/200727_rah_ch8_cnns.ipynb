{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "data_path = Path(\"../data/p1ch7/\")\n",
    "cifar10 = datasets.CIFAR10(data_path, train = True, download= True)\n",
    "cifar10_val = datasets.CIFAR10(data_path, train = False, download= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10 = datasets.CIFAR10(\n",
    "    data_path, train=True, download=False,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))\n",
    "\n",
    "cifar10_val = datasets.CIFAR10(\n",
    "    data_path, train=False, download=False,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {0:0, 2: 1}\n",
    "class_names = ['airplane', 'bird']\n",
    "cifar2 = [(img, label_map[label]) for img, label in cifar10 if label in [0, 2]]\n",
    "cifar2_val = [(img, label_map[label]) for img, label in cifar10_val if label in [0, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size = 64, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size = 64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, _ = cifar2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv =  nn.Conv2d(3, 16, kernel_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = conv(img.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 32, 32]), torch.Size([1, 16, 30, 30]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.unsqueeze(0).shape, output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(output[0,0].detach(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 32, 32]), torch.Size([1, 1, 32, 32]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = nn.Conv2d(3,1, kernel_size=3, padding=1)\n",
    "output = conv(img.unsqueeze(0))\n",
    "img.unsqueeze(0).shape, output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    conv.bias.zero_()\n",
    "    \n",
    "with torch.no_grad():\n",
    "    conv.weight.fill_(1.0 / 9.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 32, 32]),\n",
       " torch.Size([1, 3, 32, 32]),\n",
       " torch.Size([3, 32, 32, 1]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape, img.unsqueeze(0).shape, img.unsqueeze(-1).shape # unsqueeze add an extra dimension at idx..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "output = conv(img.unsqueeze(0))\n",
    "plt.imshow(output[0,0].detach(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(3,1, kernel_size = 3, padding = 1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    conv.weight[:] = torch.tensor([[-1.0, 0.0, 1.0], \n",
    "                                   [-1.0, 0.0, 1.0], \n",
    "                                   [-1.0, 0.0, 1.0]])\n",
    "    \n",
    "    conv.bias.zero_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "output = conv(img.unsqueeze(0))\n",
    "plt.imshow(output[0,0].detach(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 32, 32]), torch.Size([1, 3, 16, 16]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool = nn.MaxPool2d(2)\n",
    "output = pool(img.unsqueeze(0))\n",
    "img.unsqueeze(0).shape, output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instead of Softmax and NLLLoss we can combine and use CrossEntropyLoss\n",
    "\n",
    "model = nn.Sequential(nn.Conv2d(3, 16, kernel_size = 3, padding = 1),\n",
    "                      nn.Tanh(), \n",
    "                      nn.MaxPool2d(2),\n",
    "                      nn.Conv2d(16, 8, kernel_size = 3, padding = 1),\n",
    "                      nn.Tanh(),\n",
    "                      nn.MaxPool2d(2),\n",
    "                      ## Need to add a subclass to reshape\n",
    "                      nn.Linear(8*8*8, 32),\n",
    "                      nn.Tanh(),\n",
    "                      nn.Linear(32, 2)\n",
    "                     )\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Not so fast..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create our network as an nn.Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Net class is equivalent to the nn.Sequential model but we can explicitly manipulate the output of self.pool3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size = 3, padding = 1) # Input: (3 channel, 32 x 32) Output: (16 channel, 32x32)\n",
    "        self.act1 = nn.Tanh()\n",
    "        self.pool1 = nn.MaxPool2d(2) #Output: 16C x 16 x 16\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size = 3, padding = 1) # Input: (16C x 16 x 16) Output: (8C x 16 x 16)\n",
    "        self.act2 = nn.Tanh()\n",
    "        self.pool2 = nn.MaxPool2d(2) # Output: 8C x 8 x 8\n",
    "        self.fc1 = nn.Linear(8*8*8, 32) # Output: (1 x 32)\n",
    "        self.act3 = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(32, 2) # Output: (1 x 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.pool1(self.act1(self.conv1(x)))\n",
    "        out = self.pool2(self.act2(self.conv2(out)))\n",
    "        out = out.view(-1, 8*8*8) # What we were missing before. Converts to a \n",
    "        out = self.act3(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important: \n",
    "\n",
    "Our goal is reflected by the size of our intermediate values generally\n",
    "shrinking—this is done by reducing the number of channels in the convolutions, by\n",
    "reducing the number of pixels through pooling, and by having an output dimension\n",
    "lower than the input dimension in the linear layers. This is a common trait of\n",
    "classification networks. However, in many popular architectures like the ResNets we saw\n",
    "in chapter 2 and discuss more in section 8.5.3, the reduction is achieved by pooling in\n",
    "the spatial resolution, but the number of channels increases (still resulting in a\n",
    "reduction in size). It seems that our pattern of fast information reduction works well\n",
    "with networks of limited depth and small images; but for deeper networks, the decrease\n",
    "is typically slower.\n",
    "\n",
    "Second, in one layer, there is not a reduction of output size with regard to input\n",
    "size: the initial convolution. If we consider a single output pixel as a vector of 32 ele-\n",
    "ments (the channels), it is a linear transformation of 27 elements (as a convolution of\n",
    "3 channels × 3 × 3 kernel size)—only a moderate increase. In ResNet, the initial con-\n",
    "volution generates 64 channels from 147 elements (3 channels × 7 × 7 kernel size). 6\n",
    "So the first layer is exceptional in that it greatly increases the overall dimension (as in\n",
    "channels times pixels) of the data flowing through it, but the mapping for each out-\n",
    "put pixel considered in isolation still has approximately as many outputs as inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size = 3, padding = 1)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size = 3, padding = 1)\n",
    "        self.fc1 = nn.Linear(8*8*8, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = out.view(-1, 8*8*8) # What we were missing before. Converts to a \n",
    "        out = torch.tanh((self.fc1(out)))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0262,  0.0429]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "model(img.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now lets run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader: # Loops over our dataset in the batches the data loader creates for us\n",
    "            \n",
    "            outputs = model(imgs) # feeds a batch through our model\n",
    "            \n",
    "            loss = loss_fn(outputs, labels) # computes the loss we wish to minimize\n",
    "            \n",
    "            optimizer.zero_grad() # After getting rid of the gradients from the last round\n",
    "            \n",
    "            loss.backward() # performs the backward step. Computes gradients\n",
    "            \n",
    "            optimizer.step() # updates the model\n",
    "            \n",
    "            loss_train += loss.item() # Sums the losses over the epoch\n",
    "             \n",
    "        if epoch == 1 or epoch %10 == 0:\n",
    "            print(f'{datetime.datetime.now()} Epoch {epoch}, Training Loss {loss_train/len(train_loader)}') # Divides by the length of training data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-30 19:39:21.385644 Epoch 1, Training Loss 0.5432194188521926\n",
      "2020-07-30 19:39:46.647205 Epoch 10, Training Loss 0.3215288723919802\n",
      "2020-07-30 19:40:20.222261 Epoch 20, Training Loss 0.2971838532359737\n",
      "2020-07-30 19:40:56.640202 Epoch 30, Training Loss 0.2770054606115742\n",
      "2020-07-30 19:41:31.021992 Epoch 40, Training Loss 0.25808606263558576\n",
      "2020-07-30 19:42:02.347880 Epoch 50, Training Loss 0.2386671416224188\n",
      "2020-07-30 19:42:33.350180 Epoch 60, Training Loss 0.22322263312377746\n",
      "2020-07-30 19:43:03.658713 Epoch 70, Training Loss 0.20428616121696058\n",
      "2020-07-30 19:43:32.549143 Epoch 80, Training Loss 0.19093755732296377\n",
      "2020-07-30 19:44:01.620535 Epoch 90, Training Loss 0.17797070065406478\n",
      "2020-07-30 19:44:30.923696 Epoch 100, Training Loss 0.16130188031561055\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size = 64, shuffle = True)\n",
    "\n",
    "model = Net()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(n_epochs = 100, \n",
    "              optimizer = optimizer, \n",
    "              model = model, \n",
    "              loss_fn = loss_fn, \n",
    "              train_loader = train_loader\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size = 64, shuffle = False)\n",
    "\n",
    "def validate(model, train_loader, val_loader):\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad(): # We do not want gradients here. Not update parameters\n",
    "            for imgs, labels in loader:\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim = 1)\n",
    "                total += labels.shape[0]\n",
    "                correct += int((predicted == labels).sum()) # Cast to a python int which is eqivalent to using .item()\n",
    "        \n",
    "        print(f\"Accuracy {name}: {correct/total:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.94\n",
      "Accuracy val: 0.89\n"
     ]
    }
   ],
   "source": [
    "validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and loading our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model with just weights, no struture. This means when we deploy the model in production we'll need to keep the model class handy, create an instance and then load the parameters back in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), Path('../models') /'birds_vs_airplanes.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = Net()\n",
    "loaded_model.load_state_dict(torch.load(Path('../models/birds_vs_airplanes.pt')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move to GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
    "print(f'Training on device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader, device):\n",
    "    print(f'Training on device: {device}')\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader: # Loops over our dataset in the batches the data loader creates for us\n",
    "            imgs = imgs.to(device = device)\n",
    "            labels = labels.to(device = device)\n",
    "            outputs = model(imgs) # feeds a batch through our model\n",
    "            \n",
    "            loss = loss_fn(outputs, labels) # computes the loss we wish to minimize\n",
    "            \n",
    "            optimizer.zero_grad() # After getting rid of the gradients from the last round\n",
    "            \n",
    "            loss.backward() # performs the backward step. Computes gradients\n",
    "            \n",
    "            optimizer.step() # updates the model\n",
    "            \n",
    "            loss_train += loss.item() # Sums the losses over the epoch\n",
    "             \n",
    "        if epoch == 1 or epoch %10 == 0:\n",
    "            print(f'{datetime.datetime.now()} Epoch {epoch}, Training Loss {loss_train/len(train_loader)}')\n",
    "            \n",
    "def validate(model, train_loader, val_loader, device):\n",
    "    print(f'Validating on device: {device}')\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad(): # We do not want gradients here. Not update parameters\n",
    "            for imgs, labels in loader:\n",
    "                imgs = imgs.to(device = device)\n",
    "                labels = labels.to(device = device)\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim = 1)\n",
    "                total += labels.shape[0]\n",
    "                correct += int((predicted == labels).sum()) # Cast to a python int which is eqivalent to using .item()\n",
    "        \n",
    "        print(f\"Accuracy {name}: {correct/total:.2f}\")            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device: cpu\n",
      "2020-07-30 19:57:02.319873 Epoch 1, Training Loss 0.5888296392313235\n",
      "2020-07-30 19:57:29.241184 Epoch 10, Training Loss 0.3416705160004318\n",
      "2020-07-30 19:57:55.973133 Epoch 20, Training Loss 0.3038936392137199\n",
      "2020-07-30 19:58:29.083305 Epoch 30, Training Loss 0.2781128836617728\n",
      "2020-07-30 19:58:58.490721 Epoch 40, Training Loss 0.2590417129218958\n",
      "2020-07-30 19:59:26.471722 Epoch 50, Training Loss 0.23878861479698474\n",
      "2020-07-30 19:59:55.473393 Epoch 60, Training Loss 0.22182096697532447\n",
      "2020-07-30 20:00:25.010400 Epoch 70, Training Loss 0.20277301245813917\n",
      "2020-07-30 20:00:54.537306 Epoch 80, Training Loss 0.18896448972878183\n",
      "2020-07-30 20:01:23.122081 Epoch 90, Training Loss 0.17564612036203123\n",
      "2020-07-30 20:01:53.061770 Epoch 100, Training Loss 0.1623483489320916\n",
      "2020-07-30 20:02:21.879279 Epoch 110, Training Loss 0.15035343445410396\n",
      "2020-07-30 20:02:50.617864 Epoch 120, Training Loss 0.13629933094285476\n",
      "2020-07-30 20:03:19.572419 Epoch 130, Training Loss 0.12722024366639223\n",
      "2020-07-30 20:03:47.647983 Epoch 140, Training Loss 0.11307278000245428\n",
      "2020-07-30 20:04:16.652578 Epoch 150, Training Loss 0.10417548624003768\n",
      "Validating on device: cpu\n",
      "Accuracy train: 0.94\n",
      "Accuracy val: 0.89\n"
     ]
    }
   ],
   "source": [
    "device = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
    "\n",
    "model = Net().to(device=device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr = 1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(n_epochs = 150, \n",
    "              optimizer = optimizer, \n",
    "              model = model, \n",
    "              loss_fn = loss_fn, \n",
    "              train_loader = train_loader,\n",
    "              device = device\n",
    "             )\n",
    "\n",
    "validate(model, train_loader, val_loader, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), Path('../models') /'birds_vs_airplanes.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explicityl label PyTorch to override the device info when loading weights via map location\n",
    "loaded_model = Net().to(device=device)\n",
    "loaded_model.load_state_dict(torch.load(Path('../models') /'birds_vs_airplanes.pt', map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add skip connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetDepth(nn.Module):\n",
    "    def __init__(self, n_chans1 = 32):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size = 3, padding = 1)\n",
    "        self.conv2 = nn.Conv2d(n_chans1, n_chans1//2, kernel_size = 3, padding = 1)\n",
    "        self.conv3 = nn.Conv2d(n_chans1//2, n_chans1//2, kernel_size = 3, padding = 1)\n",
    "        self.fc1 = nn.Linear(4*4*n_chans1//2, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n",
    "        out1 = out\n",
    "        out = F.max_pool2d(torch.relu(self.conv3(out)) + out1, 2) # Add the output of the first layer in teh forward function to the input of the third layer. A \"residual\"\n",
    "        out = out.view(-1, 4*4*self.n_chans1//2) \n",
    "        out = torch.relu((self.fc1(out)))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
